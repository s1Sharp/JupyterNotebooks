{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Toolkit (NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import Text\n",
    "tokens = word_tokenize('Here is some not very interesting text')\n",
    "text = Text(tokens)\n",
    "print('Всего слов ',len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Этот код загружает девять книг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с text6 \"Monty Python and the Holy Grail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "fdist = FreqDist(text6)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "bigrams = bigrams(text6)\n",
    "bigramsDist = FreqDist(bigrams)\n",
    "bigramsDist[(\"Sir\", \"Robin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "fourgrams = ngrams(text6, 4)\n",
    "fourgramsDist = FreqDist(fourgrams)\n",
    "fourgramsDist[(\"father\", \"smelt\", \"of\", \"elderberries\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgrams = ngrams(text6, 4)\n",
    "for fourgram in fourgrams:\n",
    " if fourgram[0] == \"coconut\":\n",
    "  print(fourgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лексикографический анализ текста с помощью библиотеки nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор тегов Penn Treebank\n",
    "Alphabetical list of part-of-speech tags used in the Penn Treebank Project:\n",
    "Number Tag  Description\n",
    "* \n",
    "1. CC Coordinating conjunction \n",
    "2. CD Cardinal number \n",
    "3. DT Determiner \n",
    "4. EX Existential there \n",
    "5. FW Foreign word \n",
    "6. IN Preposition or subordinating conjunction \n",
    "7. JJ Adjective \n",
    "8. JJR Adjective, comparative \n",
    "9. JJS Adjective, superlative \n",
    "10. LS List item marker \n",
    "11. MD Modal \n",
    "12. NN Noun, singular or mass \n",
    "13. NNS Noun, plural \n",
    "14. NNP Proper noun, singular \n",
    "15. NNPS Proper noun, plural \n",
    "16. PDT Predeterminer \n",
    "17. POS Possessive ending \n",
    "18. PRP Personal pronoun \n",
    "19. PRPS Possessive pronoun \n",
    "20. RB Adverb \n",
    "21. RBR Adverb, comparative \n",
    "22. RBS Adverb, superlative \n",
    "23. RP Particle \n",
    "24. SYM Symbol \n",
    "25. TO to \n",
    "26. UH Interjection \n",
    "27. VB Verb, base form \n",
    "28. VBD Verb, past tense \n",
    "29. VBG Verb, gerund or present participle \n",
    "30. VBN Verb, past participle \n",
    "31. VBP Verb, non-3rd person singular present \n",
    "32. VBZ Verb, 3rd person singular present \n",
    "33. WDT Wh-determiner \n",
    "34. WP Wh-pronoun \n",
    "35. WPS Possessive wh-pronoun \n",
    "36. WRB Wh-adverb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk book import *\n",
    "from nltk import word_tokenize\n",
    "text = word_tokenize(\"Strange women lying in ponds di.stri.buting swords is no \\\n",
    "basi.s for a system of government. Supreme executive power derives from a mandate \\\n",
    "from the masses, not from some farcical aquatic ceremony.\")\n",
    "from nltk import pos_tag\n",
    "pos_tag(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример сложности определения части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(\"The dust was thick so he had to dust\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий код печатает те предложеня, в которых слово  \"google\"\n",
    "употребляется в кпчестве существительного, а не глагола."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "sentences = sent_tokenize(\"Google is one of the best companies in the world. \\\n",
    "I constantly google myself to see what 1·m up to.\")\n",
    "nouns= ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "for sentence in sentences:\n",
    "    if \"google\" in sentence.lower():\n",
    "        taggedWords = pos_tag(word_tokenize(sentence))\n",
    "        for word in taggedWords:\n",
    "           if word[0].lower() == \"google\" and word[1] in nouns:\n",
    "                print( sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация – это процесс преобразования слова в его базовую форму. Разница между стемминг (stemming) и лемматизацией заключается в том, что лемматизация учитывает контекст и преобразует слово в его значимую базовую форму, тогда как стемминг просто удаляет последние несколько символов, что часто приводит к неверному значению и орфографическим ошибкам.\n",
    "Например, лемматизация правильно определила бы базовую форму «caring» и «care», в то время как стемминг отрезал бы «ing» и преобразовал ее в car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "#--------#\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\n",
    "#Создаем лемматизатор и список стоп-слов\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "#функция предобработка текста\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пример\n",
    "preprocess_text(\"Ну что сказать, я вижу кто-то списывает на экзамене, Вы разочаровали меня, приходите на пересдачу.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text(\"Hу что сказать, ну что сказать, Устроены так люди, Желают знать, желают знать, Желают знать что будет.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('scraping': conda)",
   "language": "python",
   "name": "python38164bitscrapingconda95499467248844cd86d62de1eca38182"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}